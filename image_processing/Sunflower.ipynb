{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n_RxPWdaL9YW",
        "outputId": "bc6c9e1d-45e8-46d0-f099-505f95c9e622"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (4.8.0.76)\n",
            "Requirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.10/dist-packages (from opencv-python) (1.25.2)\n"
          ]
        }
      ],
      "source": [
        "pip install opencv-python"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Set the file path file_path = '/content/drive/MyDrive/creditcard.csv'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mo5c5XowxP01",
        "outputId": "f05cdcd5-52dd-4ee4-f2e3-63bc37579da3"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import os"
      ],
      "metadata": {
        "id": "saub9loxMJsZ"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the directory where your images are located\n",
        "sunflower = '/content/drive/MyDrive/sunflowers'\n",
        "not_sunflower = '/content/drive/MyDrive/not_sunflowers'"
      ],
      "metadata": {
        "id": "WNmStRNaMM8_"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the target size for resizing\n",
        "target_size = (224, 224)  # Example target size, adjust as needed"
      ],
      "metadata": {
        "id": "g6KgyddWMpN1"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to preprocess images\n",
        "def preprocess_image(img_path, target_size):\n",
        "    # Read image using OpenCV\n",
        "    img = cv2.imread(img_path)\n",
        "    # Resize image to the target size\n",
        "    img_resized = cv2.resize(img, target_size)\n",
        "    # Convert image to float32\n",
        "    img_resized = img_resized.astype(np.float32)\n",
        "    # Normalize pixel values to be between 0 and 1\n",
        "    img_normalized = img_resized / 255.0\n",
        "    return img_normalized\n",
        "\n",
        "# Define lists to store data and labels\n",
        "data = []\n",
        "labels = []\n",
        "\n",
        "# Iterate through each image in the \"sunflowers\" directory\n",
        "for filename in os.listdir(sunflower):\n",
        "    if filename.endswith(\".jpg\") or filename.endswith(\".png\"):  # Assuming images are in jpg or png format\n",
        "        img_path = os.path.join(sunflower, filename)\n",
        "        # Preprocess the image\n",
        "        preprocessed_img = preprocess_image(img_path, target_size)\n",
        "        # Append the preprocessed image to data\n",
        "        data.append(preprocessed_img)\n",
        "        # Append the label for sunflower to labels\n",
        "        labels.append(1)  # Sunflower label is 1\n",
        "\n",
        "# Iterate through each image in the \"not_sunflowers\" directory\n",
        "for filename in os.listdir(not_sunflower):\n",
        "    if filename.endswith(\".jpg\") or filename.endswith(\".png\"): # Assuming images are in jpg or png format\n",
        "        img_path = os.path.join(not_sunflower, filename)\n",
        "        # Preprocess the image\n",
        "        preprocessed_img = preprocess_image(img_path, target_size)\n",
        "        # Append the preprocessed image to data\n",
        "        data.append(preprocessed_img)\n",
        "        # Append the label for not sunflower to labels\n",
        "        labels.append(0)  # Not sunflower label is 0\n"
      ],
      "metadata": {
        "id": "uJqkxGG8MqYF"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert lists to NumPy arrays\n",
        "data = np.array(data)\n",
        "labels = np.array(labels)\n",
        "\n",
        "# Print the shapes of data and labels\n",
        "print(\"Data shape:\", data.shape)\n",
        "print(\"Labels shape:\", labels.shape)\n",
        "\n",
        "# Print the number of unique labels/classes\n",
        "num_classes = len(np.unique(labels))\n",
        "print(\"Number of classes:\", num_classes)\n",
        "\n",
        "# Print the unique classes and their counts\n",
        "unique_classes, class_counts = np.unique(labels, return_counts=True)\n",
        "for i, class_label in enumerate(unique_classes):\n",
        "    print(\"Class\", class_label, \":\", class_counts[i])\n",
        "\n",
        "# Print a sample of data and corresponding label\n",
        "print(\"Sample data:\", data[0])  # Print the first sample data\n",
        "print(\"Sample label:\", labels[0])  # Print the corresponding label of the first sample\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TGJ1OJPPdb6D",
        "outputId": "0e790ca2-d382-46c8-d274-2a8fd33796a0"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data shape: (223, 224, 224, 3)\n",
            "Labels shape: (223,)\n",
            "Number of classes: 2\n",
            "Class 0 : 86\n",
            "Class 1 : 137\n",
            "Sample data: [[[0.34117648 0.23529412 0.19607843]\n",
            "  [0.34117648 0.23529412 0.19607843]\n",
            "  [0.34509805 0.23921569 0.2       ]\n",
            "  ...\n",
            "  [0.35686275 0.26666668 0.23529412]\n",
            "  [0.35686275 0.26666668 0.23529412]\n",
            "  [0.3529412  0.2627451  0.23137255]]\n",
            "\n",
            " [[0.34117648 0.23529412 0.19607843]\n",
            "  [0.34117648 0.23529412 0.19607843]\n",
            "  [0.34509805 0.23921569 0.2       ]\n",
            "  ...\n",
            "  [0.35686275 0.26666668 0.23529412]\n",
            "  [0.35686275 0.26666668 0.23529412]\n",
            "  [0.3529412  0.2627451  0.23137255]]\n",
            "\n",
            " [[0.34509805 0.23921569 0.2       ]\n",
            "  [0.34509805 0.23921569 0.2       ]\n",
            "  [0.34901962 0.24313726 0.20392157]\n",
            "  ...\n",
            "  [0.36078432 0.27058825 0.23921569]\n",
            "  [0.36078432 0.27058825 0.23921569]\n",
            "  [0.35686275 0.26666668 0.23529412]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[0.02352941 0.04313726 0.03529412]\n",
            "  [0.02352941 0.04313726 0.03529412]\n",
            "  [0.02745098 0.04705882 0.03921569]\n",
            "  ...\n",
            "  [0.03137255 0.05098039 0.04705882]\n",
            "  [0.03137255 0.05098039 0.04705882]\n",
            "  [0.03137255 0.05098039 0.04705882]]\n",
            "\n",
            " [[0.01960784 0.03921569 0.03137255]\n",
            "  [0.01960784 0.03921569 0.03137255]\n",
            "  [0.02352941 0.04313726 0.03529412]\n",
            "  ...\n",
            "  [0.03137255 0.05098039 0.04705882]\n",
            "  [0.03137255 0.05098039 0.04705882]\n",
            "  [0.03137255 0.05098039 0.04705882]]\n",
            "\n",
            " [[0.01568628 0.03529412 0.02745098]\n",
            "  [0.01960784 0.03921569 0.03137255]\n",
            "  [0.02352941 0.04313726 0.03529412]\n",
            "  ...\n",
            "  [0.03137255 0.05098039 0.04705882]\n",
            "  [0.03137255 0.05098039 0.04705882]\n",
            "  [0.03137255 0.05098039 0.04705882]]]\n",
            "Sample label: 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "O6FmdDHu9uTt"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Split the dataset into training, validation, and testing sets\n",
        "# Here, we'll split the data into 80% training, 10% validation, and 10% testing sets\n",
        "# You can adjust the test_size and validation_size parameters as needed\n",
        "train_data, test_data, train_labels, test_labels = train_test_split(data, labels, test_size=0.2, random_state=42)\n",
        "train_data, val_data, train_labels, val_labels = train_test_split(train_data, train_labels, test_size=0.125, random_state=42)\n",
        "\n",
        "# Optionally, you can print the shapes of the data splits to verify the sizes\n",
        "print(\"Train data shape:\", train_data.shape)\n",
        "print(\"Train labels shape:\", train_labels.shape)\n",
        "print(\"Validation data shape:\", val_data.shape)\n",
        "print(\"Validation labels shape:\", val_labels.shape)\n",
        "print(\"Test data shape:\", test_data.shape)\n",
        "print(\"Test labels shape:\", test_labels.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4g3MsUu8MtrY",
        "outputId": "5492f3cd-eec0-4676-dc7a-fb4ac89149c7"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train data shape: (155, 224, 224, 3)\n",
            "Train labels shape: (155,)\n",
            "Validation data shape: (23, 224, 224, 3)\n",
            "Validation labels shape: (23,)\n",
            "Test data shape: (45, 224, 224, 3)\n",
            "Test labels shape: (45,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import accuracy_score"
      ],
      "metadata": {
        "id": "quwi3kXzBm8t"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define and train models\n",
        "svm_model = SVC(kernel='linear')  # Support Vector Machine with linear kernel\n",
        "svm_model.fit(train_data.reshape(train_data.shape[0], -1), train_labels)\n",
        "\n",
        "svm_pred = svm_model.predict(val_data.reshape(val_data.shape[0], -1))\n",
        "svm_accuracy = accuracy_score(val_labels, svm_pred)\n",
        "print(\"SVM Accuracy:\", svm_accuracy)\n"
      ],
      "metadata": {
        "id": "PrW1cYa0BmwP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bdc8bdb8-2973-47a2-d644-b9610f28cb24"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SVM Accuracy: 0.8695652173913043\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rf_model = RandomForestClassifier(n_estimators=100)  # Random Forest Classifier\n",
        "rf_model.fit(train_data.reshape(train_data.shape[0], -1), train_labels)\n",
        "\n",
        "rf_pred = rf_model.predict(val_data.reshape(val_data.shape[0], -1))\n",
        "rf_accuracy = accuracy_score(val_labels, rf_pred)\n",
        "print(\"Random Forest Accuracy:\", rf_accuracy)"
      ],
      "metadata": {
        "id": "nEy8KQK_BmTR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "64478477-0238-428d-c211-d2940723d3d9"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random Forest Accuracy: 0.782608695652174\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "knn_model = KNeighborsClassifier(n_neighbors=5)  # K-Nearest Neighbors Classifier\n",
        "knn_model.fit(train_data.reshape(train_data.shape[0], -1), train_labels)\n",
        "\n",
        "knn_pred = knn_model.predict(val_data.reshape(val_data.shape[0], -1))\n",
        "knn_accuracy = accuracy_score(val_labels, knn_pred)\n",
        "print(\"KNN Accuracy:\", knn_accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eCqg4GUJE7x2",
        "outputId": "0fa0c838-b14e-4e72-a442-7f461a95f7d4"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "KNN Accuracy: 0.6956521739130435\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models"
      ],
      "metadata": {
        "id": "u8oUYJG9FHgJ"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the CNN architecture\n",
        "model = models.Sequential([\n",
        "    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(224, 224, 3)),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "    layers.Conv2D(128, (3, 3), activation='relu'),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "    layers.Flatten(),\n",
        "    layers.Dense(128, activation='relu'),\n",
        "    layers.Dense(1, activation='sigmoid')\n",
        "])\n"
      ],
      "metadata": {
        "id": "vQZ4ndl1F3X6"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile the model\n",
        "model.compile(optimizer='adam',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Print the model summary\n",
        "model.summary()\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(train_data, train_labels, epochs=10, batch_size=32, validation_data=(val_data, val_labels))\n",
        "\n",
        "# Evaluate the model on the test set\n",
        "test_loss, test_accuracy = model.evaluate(test_data, test_labels)\n",
        "print(\"Test Accuracy:\", test_accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XG8DsW0sF7xm",
        "outputId": "cce3c12c-699c-44ff-9e89-4ab9106d6bc7"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 222, 222, 32)      896       \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2  (None, 111, 111, 32)      0         \n",
            " D)                                                              \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 109, 109, 64)      18496     \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPoolin  (None, 54, 54, 64)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 52, 52, 128)       73856     \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPoolin  (None, 26, 26, 128)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 86528)             0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 128)               11075712  \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 1)                 129       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 11169089 (42.61 MB)\n",
            "Trainable params: 11169089 (42.61 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "5/5 [==============================] - 28s 5s/step - loss: 2.9734 - accuracy: 0.5355 - val_loss: 0.6921 - val_accuracy: 0.3913\n",
            "Epoch 2/10\n",
            "5/5 [==============================] - 29s 6s/step - loss: 0.6602 - accuracy: 0.6000 - val_loss: 0.6052 - val_accuracy: 0.6087\n",
            "Epoch 3/10\n",
            "5/5 [==============================] - 20s 4s/step - loss: 0.5494 - accuracy: 0.7097 - val_loss: 0.6181 - val_accuracy: 0.6087\n",
            "Epoch 4/10\n",
            "5/5 [==============================] - 18s 4s/step - loss: 0.5196 - accuracy: 0.7161 - val_loss: 0.5065 - val_accuracy: 0.7826\n",
            "Epoch 5/10\n",
            "5/5 [==============================] - 18s 4s/step - loss: 0.3771 - accuracy: 0.8452 - val_loss: 0.4779 - val_accuracy: 0.7826\n",
            "Epoch 6/10\n",
            "5/5 [==============================] - 19s 4s/step - loss: 0.2965 - accuracy: 0.8710 - val_loss: 0.5990 - val_accuracy: 0.6957\n",
            "Epoch 7/10\n",
            "5/5 [==============================] - 18s 4s/step - loss: 0.3036 - accuracy: 0.8581 - val_loss: 0.4679 - val_accuracy: 0.7391\n",
            "Epoch 8/10\n",
            "5/5 [==============================] - 27s 6s/step - loss: 0.1959 - accuracy: 0.9290 - val_loss: 0.5484 - val_accuracy: 0.8261\n",
            "Epoch 9/10\n",
            "5/5 [==============================] - 23s 4s/step - loss: 0.1473 - accuracy: 0.9484 - val_loss: 0.5063 - val_accuracy: 0.8261\n",
            "Epoch 10/10\n",
            "5/5 [==============================] - 18s 4s/step - loss: 0.0992 - accuracy: 0.9613 - val_loss: 0.4898 - val_accuracy: 0.8696\n",
            "2/2 [==============================] - 1s 341ms/step - loss: 0.7134 - accuracy: 0.7778\n",
            "Test Accuracy: 0.7777777910232544\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Flatten the image data\n",
        "num_samples = train_data.shape[0]\n",
        "num_features = np.prod(train_data.shape[1:])\n",
        "train_data_flat = train_data.reshape(num_samples, num_features)\n",
        "\n",
        "# Create the ensemble model\n",
        "ensemble_clf = VotingClassifier(estimators=[\n",
        "    ('rf', rf_clf),\n",
        "    ('knn', knn_clf),\n",
        "    ('svc', svc_clf)\n",
        "], voting='soft')  # Using soft voting for probabilities\n",
        "\n",
        "# Train the ensemble model\n",
        "ensemble_clf.fit(train_data_flat, train_labels)\n",
        "\n",
        "# Flatten the test data as well\n",
        "num_samples_test = test_data.shape[0]\n",
        "test_data_flat = test_data.reshape(num_samples_test, num_features)\n",
        "\n",
        "# Evaluate the ensemble model\n",
        "ensemble_preds = ensemble_clf.predict(test_data_flat)\n",
        "ensemble_accuracy = accuracy_score(test_labels, ensemble_preds)\n",
        "print(\"Ensemble Accuracy:\", ensemble_accuracy)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZAWBLSTsfGzA",
        "outputId": "72f5627a-16b7-4ff9-bb9d-e04acb93e379"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ensemble Accuracy: 0.7333333333333333\n"
          ]
        }
      ]
    }
  ]
}